{
  "cells": [
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# Создаём свой когнитивный портрет\n\nПривет! Сейчас мы погрузимся в мир **Science Art**, где наука -- а именно **искусственный интеллект** -- поможет нам создавать произведения искусства! А именно, мы познакомимся с техникой [когнитивного аддитивного портрета](http://bit.do/peopleblending)\n\n<img src=\"https://raw.githubusercontent.com/shwars/FaceArt/master/notebooks/img/PhoBoGuy.png\" width=\"30%\"/>\n\nВ этой технике мы используем **[Face API](https://docs.microsoft.com/azure/cognitive-services/face/overview/?wt.mc_id=digigirlz-event-dmitryso)** для выделения ключевых точек лица на серии фотографий, с последующим поворотом и масштабированием фотографий таким образом, чтобы глаза на всех снимках совпадали. Совмещая такие снимки, мы получаем интересный визуальный эффект. \n\n"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Используем Python и Azure Notebook\n\nДля создания портрета мы будем использовать язык программирования Python. Не волнуйтесь, чтобы получить портрет вам не придётся писать свой код, а только выполнять существующий! Однако если вы умеете программировать (или научитесь это делать), то сможете получать намного более интересные визуальные эффекты! Научиться языку программирования Python можно с помощью [этого курса](http://pythontutor.ru).\n\nДля выполнения нашей программы мы будем использовать так называемый [Azure Notebook](http://bit.do/whyaznb). Это доумент, в котором есть ячейки с текстом (одну из них вы сейчас читаете) и ячейки с кодом на языке Python - слева от таких ячеек есть надпись `In [..]`. Такую ячейку с кодом можно **выполнить**, нажав кнопку **RUN** в верхней панели или комбинацию клавиш **Ctrl-Enter**, при этом результат будет виден ниже под ячейкой. Попробуйте выполнить ячейку ниже, в которой мы вычисляем число секунд в сутках: "
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "24*60*60",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Для рисования портрета нам потребуется выполнить ряд ячеек с кодом. Это надо делать последовательно, дожидаясь завершения выполнения предыдущей ячейки (в процессе выполнения надпись слева выглядит как `In [*]`, а после выполнения звёздочка заменяется номером, показывающим, какой по счету была выполнена эта ячейка).\n\nВ упражнении ниже мы примерно описываем, что делает программа в каждой из ячеек: что-то будет вам понятно, что-то - нет. Не волнуйтесь, это нормально!"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Установка необходимых библиотек\n\nМногие сложные операции в языке Python делаются с помощью специальных **библиотек**, т.е. написанных кем-то заранее программ. Для проведения манипуляций с изображениями нам необходима библиотека **OpenCV**, а также нужна библиотека для работы с **Face API**. В начале работы нам необходимо установить эти библиотеки (с помошью команд `pip`) и **импортировать** их, чтобы Python в дальнейшем видел все необходимые функции. \n\nСледующая ячейка с командами может работать довольно долго, потому что она скачивает и устанавливает библиотеки. Дождитесь результата её выполнения! Если вы увидите предупредительное сообщение *WARNING* -- не переживайте, это нормально."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "import sys\n!{sys.executable} -m pip install --quiet opencv-python azure-cognitiveservices-vision-face",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "import os, requests, glob\nimport cv2\nimport matplotlib.pyplot as plt\nimport numpy as np",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Извлекаем опорные точки лица\n\nДля извлечения опорных точек лица мы используем [Microsoft Face API](https://azure.microsoft.com/services/cognitive-services/face/?wt.mc_id=digigirlz-event-dmitryso). С помощью него мы можем извлечь много полезной информации о лице, включая пол, возраст, углы поворота головы, эмоции и ключевые точки:\n\n![Facial Landmarks](https://raw.githubusercontent.com/shwars/FaceArt/master/notebooks/img/landmarks.jpg)\n\nДля более подробной информации о Face API и о том, как использовать его из других языков программирования, [посетите документацию на Microsoft Docs](https://docs.microsoft.com/ru-ru/azure/cognitive-services/face/index/?wt.mc_id=digigirlz-event-dmitryso)."
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Для использования Face API нам необходим специальный ключ, а также интернет-адрес для вызова сервиса (Endpoint URL). Самый простой способ его получить - запросить 7-дневный пробный ключ. При этом вам будет достаточно войти на страничку со своим **Microsoft Account**, и сказать **получить ключ*\n\n### [Нажмите сюда для запроса ключа Face API](https://azure.microsoft.com/try/cognitive-services/my-apis/?api=face-api&wt.mc_id=digigirlz-event-dmitryso)\n\nПосле этого вам нужно скопировать один из двух **ключей** (последовательность цифр) и **конечную точку** (которая напоминает интернет-адрес) в ячейку ниже: "
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "key = '--INSERT YOUR KEY HERE--' # ключ выглядит примерно так: 'e408f9b7c8e349ee8f5567dbea67df30'\nendpoint = 'https://westus2.api.cognitive.microsoft.com' # убедитесь, что конечная точка соответствует тому, что вы увидели на странице\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "**ВАЖНО**: Конечная точка, указанная на веб-сайте, имеет вид: `https://westus2.api.cognitive.microsoft.com/api/face/1.0`. Вам необходимо удалить конечную часть адреса `/api/face/1.0`, оставив только адрес сайта. Если этого не сделать - на следующем шаге вы получите ошибку!"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Если вы скопировали все данные правильно, то после выполнения следующей ячейки вы увидите координаты опорных точек лица для следующей фотографии, взятой из интернет:\n\n<img src=\"https://2016.dotnext-piter.ru/assets/images/people/soshnikov.jpg\" width=\"20%\"/>"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "import azure.cognitiveservices.vision.face as cf\nfrom msrest.authentication import CognitiveServicesCredentials\ncli = cf.FaceClient(endpoint,CognitiveServicesCredentials(key))\nface_url = 'https://2016.dotnext-piter.ru/assets/images/people/soshnikov.jpg'\nres = cli.face.detect_with_url(face_url,return_face_landmarks=True)\nprint(res[0].face_landmarks.as_dict())",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "**ВАЖНО**: Если вы не увидели координаты опорных точек, а вместо этого появилось сообщение об ошибке - проверьте правильность ключа и конечной точки. Только после того, как эта ячейка заработает, можно идти дальше."
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Загружаем свои изображения\n\nДля экспериментов нам нужны портретные изображения. Чтобы нарисовать свой портрет, вам потребуется загрузить в директорую `images` несколько (от 5 до 15, но не больше 20) своих фотографий. Для удобства в этой директории уже находятся пара фотографий - удалите их, если вы не хотите, чтобы они тоже участвовали в генерации портрета. Но можете и оставить :)\n\nДля загрузки изображений надо перейти в предыдущую вкладку браузера, в которой находятся все файлы нашей библиотеки с примерами. Далее следуйте указаниям (показаны цифрами на рисунке):\n\n1. Переходим в директорию `images`\n2. Нажимаем в правом верхнем углу кнопку загрузки (со стрелкой) и выбираем **Upload from Computer**\n3. Перетаскиваем картинки из проводника на нашем компьютере в открывшееся окошко, или нажимаем кнопку **Choose Files** и выбираем свои фотографии на диске компьютера\n4. После этого все файлы должны появиться в списке ниже\n5. Ставим галочку напротив **I trust the contents of those files**\n6. Нажимаем **Upload**\n7. После завершения загрузки надпись Upload поменяется на **Done**, нажимаем на кнопку ещё раз.\n\n|![Upload Screen 1](.img/Upload1.PNG) | ![Upload Screen 2](.img/Upload2.PNG) |\n| ---| ----|\n"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Теперь, когда мы загрузили фотографии, посмотрим, как Face API справляется с обнаружением ключевых точек лица на этих фотографиях:"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "def imread(fn):\n    im = cv2.imread(fn)\n    return cv2.cvtColor(im,cv2.COLOR_BGR2RGB) if im is not None else None\n\nfn = glob.glob('images/*')[0]\nprint('Анализируем изображение: ',fn)\n\nimg = imread(fn)\ncli.face.detect_with_url(face_url)\nwith open(fn,'rb') as f:\n    res = cli.face.detect_with_stream(f,return_face_landmarks=True)\nfor k,v in res[0].face_landmarks.as_dict().items():\n    cv2.circle(img,(int(v['x']),int(v['y'])),7,(255,255,0),5)\nplt.imshow(img)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Для наших экспериментов, давайте загрузим первые 20 изображений, пропустим их через Face API и извлечём ключевые точки. Мы сохраним картинки в список `images`, а коорданиты точек - в список `imagepoints`.\n\n**Важно**: пробная версия Face API позволяет обрабатывать не более 20 запросов в минуту. Поэтому если вы захотите создавать портреты из более, чем 20 фотографий, то вам придётся усложнить код, добавив задержку между вызовами, чтобы количество запросов в минуту не превышало 20. В нашем случае мы просто ограничим количество обрабатываемых фотографий."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "filenames = []\nimages = []\nimagepoints = []\ncli.face.detect_with_url(face_url)\nfor fn in glob.glob(\"images/*\")[0:20]:\n    print(\"Обрабатываю картинку {} \".format(fn),end='')\n    try:\n        with open(fn,'rb') as f:\n            res = cli.face.detect_with_stream(f,return_face_landmarks=True)\n    except:\n        print(' - ОШИБКА - ',end='')\n        res = []\n    print(' найдено {} лиц'.format(len(res)))\n    if len(res)>0:\n        filenames.append(fn)\n        images.append(imread(fn))\n        imagepoints.append(res[0].face_landmarks.as_dict())",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "**Важно**: Если вдруг вы увидите сообщение **ОШИБКА**, это означает, что Face API не смогло понять вашу фотографию. Возможно, формат изображения не поддерживается, или фотография слишком хорошего качества (у Face API есть ограничение на размер поддерживаемых фотографий). Попробуйте уменьшить изображение и загрузить его снова. Однако если несколько картинок оказались с ошибкой - не беда, главное, чтобы какое-то количество лиц было найдено!"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Посмотрим на несколько загруженных нами изображений:"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "def display_images(l):\n    n=len(l)\n    fig,ax = plt.subplots(1,n)\n    for i,im in enumerate(l):\n        ax[i].imshow(im)\n        ax[i].axis('off')\n    fig.set_size_inches(fig.get_size_inches()*n)\n    plt.tight_layout()\n    plt.show()\n\ndisplay_images(images[:5])",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Аффинные преобразования\n\nЧтобы выровнять все изображения по глазам, нам необходимо повернуть и масштабировать их. Для этого мы используем математическое понятие [**аффинного преобразования**](https://ru.wikipedia.org/wiki/Affine_transformation). Это сложное понятие, но вам не обязательно его детально понимать - главное, что мы можем применить небольшую математическую магию и совместить три точки исходного изображения (будем брать координаты двух глаз и середины рта) с заданными нами точками.\n\nБудем ориентироваться на размер финального изображения $300\\times300$ точек, тогда для координат глаз выберем точки $(130,120)$ и $(170,120)$. \n\nМагическая функция для выравнивания всех изображений будет иметь вид:"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "target_triangle = np.float32([[130.0,120.0],[170.0,120.0],[150.0,160.0]])\nsize = 300\n\ndef affine_transform(img,attrs):\n    mc_x = (attrs['mouth_left']['x']+attrs['mouth_right']['x'])/2.0\n    mc_y = (attrs['mouth_left']['y'] + attrs['mouth_right']['y']) / 2.0\n    tr = cv2.getAffineTransform(np.float32([(attrs['pupil_left']['x'],attrs['pupil_left']['y']),\n                                            (attrs['pupil_right']['x'],attrs['pupil_right']['y']),\n                                            (mc_x,mc_y)]), target_triangle)                                \n    return cv2.warpAffine(img,tr,(size,size))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Выровняем с её помощью все фотографии:"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "img_aligned = [affine_transform(i,a) for i,a in zip(images,imagepoints)]\ndisplay_images(img_aligned[:5])",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Смешивание изображений\n\nДля получения результата нам осталось смешать эти изображения. Это несложная задача, но мы используем очень мощную функцию усреднения, которая позволит нам в дальнейшем присваивать разные веса отдельным изображениям. Для начала, посмотрим как смешиваются два первых изображения: \n"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "def merge(images,wts=None):\n    res = np.zeros_like(images[0],dtype=np.float32)\n    if wts is None:\n        wts = np.ones(len(images))\n    wts /= np.sum(wts)\n    for n,i in enumerate(images):\n        res += wts[n]*i.astype(np.float32)/255.0\n    return res\n\ndisplay_images([img_aligned[0],img_aligned[1],merge(img_aligned[0:2])])",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "А теперь смешиваем все фотографии сразу, чтобы получить наш усредненный портрет!"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "res = merge(img_aligned)\nplt.imshow(res)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Мы можем сразу сгенерировать несколько изображений, смешивая картинки со случайными весами, чтобы потом выбрать из них лучший:"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "imgs = [merge(img_aligned,np.random.random(len(img_aligned))) for _ in range(5)]\ndisplay_images(imgs)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Наконец, запишем понравившийся нам портрет в JPG-файл, чтобы потом опубликовать его в instagram/twitter/vk. Для этого выполните следующую ячейку несколько раз, пока получившийся результат вас не удовлетворит:"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "res = merge(img_aligned,np.random.random(len(img_aligned)))\nplt.imshow(res)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "А теперь выполните следующую ячейку, чтобы записать результат на диск:"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "cv2.imwrite('result.jpg',(cv2.cvtColor(res,cv2.COLOR_BGR2RGB)*255.0).astype(np.int))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Теперь вы можете снова перейти к соседней вкладке браузера - к той, где вы загружали изображения. Возможно, потребуется перезагрузить страницу (нажмите **F5**), и вы увидите файл `result.jpg` и сможете его посмотреть или загрузить.\n\nТакже всегда можно скопировать изображение с экрана компьютера с помощью инструмента **ножницы**..."
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Учитесь программировать и продолжайте эксперименты!\n\nУра! Мы с вами научились создавать простейшие когнитивные портреты, накладывая фотографии для достижения интересного художественного эффекта! Вы можете поэкспериментировать с разными наборами фотографий, чтобы получить разные эффекты:\n\n* Используйте фотографии одного человека разного возраста, чтобы получить эффект \"омоложения\"\n* Комбинируйте фотографии разных людей (5 фотографий одного человека и 5 другого), чтобы смешать их вместе!\n* Попробуйте смешать много фотографий разных людей\n\nСмешивание фотографий - это лишь один приём, который можно использовать, получив координаты опорных точек лица. Вы можете делать и другие, например, поэкспериментируйте с расположением точек лица по какому-нибудь правилу, например, по окружности. Изучив возможности Python и библиотеки OpenCV по обработке изображений, вы сможете разнообразить свой творческий инструментарий, и получать действительно интересные эффекты."
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Поделитесь результатами!\n\nПожалуйста, обязательно делитесь полученными результатами! Лично мне, как автору технологии **peopleblendig**, будет очень интересно посмотреть на ваши результаты - например, вы можете [послать мне получившуюся картинку сообщением в вк](http://vk.com/shwars). Но ещё лучше - разместите их в социальных сетях с хештегом **#peopleblending**. Например:\n\n> Ого, смотрите что я сотворил с использованием технологии #peopleblending http://bit.do/peopleblending!\n\nНе останавливайтесь на достигнутом, творите и будьте счастливы!"
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "name": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}